# GENERAL NOTE: the fields denoted as meta-info are not actual configuration parameters. Instead, they are used to
# describe some characteristic of a network module that needs to be accessible from some other module but is hard to
# determine in a generic way from within the code. A typical example is the total output stride of the network body.
# These should be properly configured by the user to match the actual properties of the network.

[general]
# Number of epochs between validations
val_interval = 1
# Number of steps before outputting a log entry
log_interval = 10
# Panoptic evaluation parameters
score_threshold = 0.5
overlap_threshold = 0.5
min_stuff_area = 0
cudnn_benchmark = no

[base]
# Architecture for the body
base = efficientdet-d3
# Path to pre-trained weights
weights =
# Normalization mode:
# -- bn: in-place batch norm everywhere
# -- syncbn: synchronized in-place batch norm everywhere
# -- syncbn+bn: synchronized in-place batch norm in the static part of the network, in-place batch norm everywhere else
# -- gn: group norm everywhere
# -- syncbn+gn: synchronized in-place batch norm in the static part of the network, group norm everywhere else
# -- off: do not normalize activations (scale and bias are kept)
normalization_mode = syncbn
# Activation: 'leaky_relu' or 'elu'
activation = leaky_relu
activation_slope = 0.01
# Group norm parameters
gn_groups = 0
# Additional parameters for the body
base_params = {}
# Number of frozen modules: in [1, 5]
num_frozen = 0
# Wether to freeze BN modules
bn_frozen = no

[fpn]
fpn_channels = 256
extra_scales = 0
# Input Settings
inputs = ["mod2", "mod3", "mod4", "mod5"]
# Meta-info
out_strides = (4, 8, 16, 32)
interpolation = nearest

[transformer]
tfm_scales = (4, 8, 16, 32)
in_channels =  160
tfm_channels = 128
bev_ms_channels = 256
use_init_theta = yes
front_vertical_classes = (2, 3, 5, 7, 8, 9, 10)
front_flat_classes = (0, 1, 4, 6)
bev_vertical_classes = (2, 3, 6, 7, 8, 9)
bev_flat_classes = (0, 1, 4, 5)

[rpn]
hidden_channels = 256
stride = 1
# Anchor settings
anchor_ratios = (1., 0.5, 2.)
anchor_scale = (4, 8, 16)
# Proposal settings
nms_threshold = 0.7
num_pre_nms_train = 12000
num_post_nms_train = 2000
num_pre_nms_val = 6000
num_post_nms_val = 1000
min_size = 0
# Anchor matcher settings
num_samples = 256
pos_ratio = .5
pos_threshold = .7
neg_threshold = .3
void_threshold = 0.7
# FPN-specific settings
fpn_min_level = 0
fpn_levels = 4
# Loss settings
sigma = 3.

[roi]
roi_size = (14, 14)
# Matcher settings
num_samples = 512
pos_ratio = .25
pos_threshold = .5
neg_threshold_hi = .5
neg_threshold_lo = 0.
void_threshold = 0.7
void_is_background = no
# Prediction generator settings
nms_threshold = 0.2
score_threshold = 0.3
max_predictions = 100
# FPN-specific settings
fpn_min_level = 0
fpn_levels = 4
fpn_canonical_scale = 224
fpn_canonical_level = 2
# Loss settings
sigma = 1.
bbx_reg_weights = (10., 10., 5., 5.)

[sem]
fpn_min_level = 0
fpn_levels = 4
pooling_size = (64, 64)
# Loss settings
ohem = 0.26

[optimizer]
base_lr = 0.005
weight_decay = 0.0001
weight_decay_norm = no
momentum = 0.9
nesterov = yes
loss_weights = {"sem_loss": 1, "vf_loss": 1, "v_region_loss": 10, "f_region_loss": 10, "obj_loss": 1, "bbx_loss": 1, "roi_cls_loss": 1, "roi_bbx_loss": 1, "roi_msk_loss": 1, "po_loss": 1}

[scheduler]
epochs = 30
# Scheduler type: 'linear', 'step', 'poly' or 'multistep'
type = multistep_multigamma
# When to update the learning rate: 'batch', 'epoch'
update_mode = epoch
# Additional parameters for the scheduler
# -- linear
#   from: initial lr multiplier
#   to: final lr multiplier
# -- step
#   step_size: number of steps between lr decreases
#   gamma: multiplicative factor
# -- poly
#   gamma: exponent of the polynomial
# -- multistep
#   milestones: step indicies where the lr decreases will be triggered
# -- multistep_multigamma
#   gamma: List containing the factor wrt the base_LR by which the LR decreases 
#   lr[i] = base_lr * gamma[i]

params = {"milestones": [15, 25], "gamma": [0.5, 0.2]}
burn_in_steps = 0
burn_in_start = 0.00333

[cameras]
intrinsics = {"fx": 1266.4172, "fy": 1276.4172, "px": 816.267, "py": 491.507}
extrinsics = {"translation": (0.0, 0.6, 1.85), "rotation": (-90, 0, 180)}
bev_params = {"f": 336, "cam_z": 26}

[dataloader]
# Image size parameters
shortest_size = 900
longest_max_size = 1600
# Batch size
train_batch_size = 1
val_batch_size = 1
# Augmentation parameters
rgb_mean = (0.485, 0.456, 0.406)
rgb_std = (0.229, 0.224, 0.225)
random_flip = yes
scale = 1
bev_crop = (896, 768)
front_resize = (448, 768)
random_brightness = (0.8, 1.2)
random_contrast = (0.8, 1.2)
random_saturation = (1, 1)
random_hue = (0, 0)
# Number of worker threads
train_workers = 4
val_workers = 4
# Subsets
train_set = train
val_set = val
